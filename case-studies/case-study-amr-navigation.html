<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Autonomous Mobile Robot Navigation - YF Studio Case Study</title>
    <meta name="description"
        content="AI-powered obstacle avoidance and path planning for AMR systems with advanced computer vision.">

    <!-- Open Graph / Facebook -->
    <meta property="og:type" content="article">
    <meta property="og:url" content="https://yfstudiouk.github.io/case-studies/case-study-amr-navigation.html">
    <meta property="og:title" content="Autonomous Mobile Robot Navigation - YF Studio Case Study">
    <meta property="og:description"
        content="AI-powered obstacle avoidance and path planning for AMR systems with advanced computer vision.">
    <meta property="og:image" content="https://yfstudiouk.github.io/images/og-image.jpg">

    <!-- Twitter -->
    <meta property="twitter:card" content="summary_large_image">
    <meta property="twitter:url" content="https://yfstudiouk.github.io/case-studies/case-study-amr-navigation.html">
    <meta property="twitter:title" content="Autonomous Mobile Robot Navigation - YF Studio Case Study">
    <meta property="twitter:description"
        content="AI-powered obstacle avoidance and path planning for AMR systems with advanced computer vision.">
    <meta property="twitter:image" content="https://yfstudiouk.github.io/images/og-image.jpg">

    <!-- Canonical & Robots -->
    <link rel="canonical" href="https://yfstudiouk.github.io/case-studies/case-study-amr-navigation.html">
    <meta name="robots" content="index, follow">

    <link rel="stylesheet" href="../css/styles.css">
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&display=swap" rel="stylesheet">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css">

    <!-- Google Analytics -->
    <script src="../js/analytics.js"></script>


    <style>
        .case-study-hero {
            min-height: 60vh;
            display: flex;
            align-items: center;
            background:
                radial-gradient(circle at 20% 80%, rgba(0, 255, 255, 0.15) 0%, transparent 50%),
                radial-gradient(circle at 80% 20%, rgba(255, 0, 255, 0.1) 0%, transparent 50%),
                radial-gradient(circle at 40% 40%, rgba(128, 0, 255, 0.1) 0%, transparent 50%),
                radial-gradient(circle at 60% 60%, rgba(0, 0, 255, 0.08) 0%, transparent 50%),
                linear-gradient(135deg, #000000 0%, #0a0a0a 25%, #1a1a1a 50%, #0d1117 75%, #161b22 100%);
            color: #ff00ff;
            position: relative;
            overflow: hidden;
            border-bottom: 1px solid rgba(255, 0, 255, 0.2);
        }

        .case-study-content {
            padding: 4rem 0;
            background: linear-gradient(135deg, #000000 0%, #0a0a0a 25%, #1a1a1a 50%, #0d1117 75%, #161b22 100%);
            color: white;
        }

        .case-study-section {
            margin-bottom: 3rem;
        }

        .case-study-section h2 {
            background: linear-gradient(45deg, #ff00ff, #00ffff);
            -webkit-background-clip: text;
            -webkit-text-fill-color: transparent;
            background-clip: text;
            font-size: 2rem;
            margin-bottom: 1rem;
        }

        .case-study-section h3 {
            color: #00ffff;
            font-size: 1.5rem;
            margin-bottom: 1rem;
        }

        .tech-stack {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(200px, 1fr));
            gap: 1rem;
            margin: 2rem 0;
        }

        .tech-item {
            background: rgba(255, 0, 255, 0.1);
            border: 1px solid rgba(255, 0, 255, 0.3);
            padding: 1rem;
            border-radius: 10px;
            text-align: center;
        }

        .back-button {
            position: fixed;
            top: 20px;
            left: 20px;
            background: linear-gradient(135deg, #000000 0%, #1a1a1a 100%);
            color: #ff00ff;
            border: 2px solid rgba(255, 0, 255, 0.4);
            padding: 0.8rem 1.5rem;
            border-radius: 25px;
            text-decoration: none;
            font-weight: 600;
            box-shadow: 0 5px 15px rgba(255, 0, 255, 0.3);
            transition: all 0.3s ease;
            z-index: 1000;
        }

        .back-button:hover {
            background: linear-gradient(135deg, #ff00ff, #00ffff);
            color: #000000;
            transform: translateY(-2px);
            box-shadow: 0 8px 25px rgba(255, 0, 255, 0.5);
        }

        .case-study-section ul {
            padding-left: 2rem;
        }

        .case-study-section li {
            margin-bottom: 0.5rem;
        }

        .case-study-section h3 {
            margin-top: 2rem;
            margin-bottom: 1rem;
        }

        .case-study-section h3:first-child {
            margin-top: 0;
        }
    </style>
</head>

<body>
    <a href="../index.html" class="back-button">
        <i class="fas fa-arrow-left"></i> Back to Portfolio
    </a>

    <!-- Case Study Hero -->
    <section class="case-study-hero">
        <div class="container">
            <div class="hero-content">
                <h1 class="hero-title">
                    Autonomous Mobile Robot Navigation
                    <span class="gradient-text">AI-Powered AMR System</span>
                </h1>
                <p class="hero-description">
                    Advanced obstacle avoidance and path planning system for autonomous mobile robots
                    with real-time computer vision, achieving 99.0% collision avoidance in complex warehouse
                    environments.
                </p>
            </div>
        </div>
    </section>

    <!-- Case Study Content -->
    <section class="case-study-content">
        <div class="container">
            <!-- Project Overview -->
            <div class="case-study-section">
                <h2>Project Overview</h2>
                <p>Developed a comprehensive autonomous navigation system for industrial AMRs operating in dynamic
                    warehouse environments. The system combines computer vision, sensor fusion, and machine learning to
                    enable
                    safe autonomous operation in shared human-robot workspaces.</p>

                <div class="tech-stack">
                    <div class="tech-item">
                        <h4>Hardware</h4>
                        <p>Custom AMR Platform, NVIDIA Jetson AGX Orin, 2D/3D LiDAR, Wheel Encoders</p>
                    </div>
                    <div class="tech-item">
                        <h4>AI Framework</h4>
                        <p>ROS2, PCL, OpenCV, TensorFlow Lite</p>
                    </div>
                    <div class="tech-item">
                        <h4>Computer Vision</h4>
                        <p>YOLOv7, SLAM, Depth Estimation, Object Tracking</p>
                    </div>
                    <div class="tech-item">
                        <h4>Navigation</h4>
                        <p>A* Pathfinding, RRT*, Dynamic Window Approach</p>
                    </div>
                </div>
            </div>

            <!-- Challenge -->
            <div class="case-study-section">
                <h2>The Challenge</h2>
                <p>A logistics company needed autonomous mobile robots for warehouse inventory management and delivery
                    operations. Key challenges included:</p>
                <ul>
                    <li>Navigation in cluttered warehouse aisles</li>
                    <li>Real-time obstacle detection (forklifts, humans, pallets)</li>
                    <li>Dynamic path planning in changing layouts</li>
                    <li>Precise localization without GPS</li>
                    <li>Integration with Warehouse Management Systems (WMS)</li>
                    <li>Compliance with ISO 3691-4 safety standards</li>
                </ul>
            </div>

            <!-- Solution -->
            <div class="case-study-section">
                <h2>Our Solution</h2>
                <h3>1. Multi-Sensor Fusion System</h3>
                <p>Integrated cameras, LiDAR, IMU, and ultrasonic sensors to create a comprehensive perception system.
                    The fusion algorithm provides robust 3D mapping and localization even in challenging lighting
                    conditions.</p>

                <h3>2. Real-time Obstacle Detection</h3>
                <p>Developed a lightweight YOLOv7 model optimized for edge deployment that detects and classifies
                    obstacles in real-time. The system can identify people, vehicles, structures, and dynamic objects
                    with 95% accuracy.</p>

                <h3>3. Dynamic Path Planning</h3>
                <p>Implemented an adaptive path planning algorithm that combines A* for global planning with Dynamic
                    Window Approach for local obstacle avoidance. The system recalculates paths in real-time based on
                    changing environments.</p>

                <h3>4. SLAM Integration</h3>
                <p>Integrated Simultaneous Localization and Mapping (SLAM) for navigation in GPS-denied warehouses.
                    The system builds and maintains 2D/3D maps while tracking the robot's position with centimeter-level
                    accuracy using LiDAR and wheel odometry.</p>
            </div>

            <!-- Technical Implementation -->
            <div class="case-study-section">
                <h2>Technical Implementation</h2>
                <h3>Perception Pipeline</h3>
                <p>The perception system processes multiple sensor inputs:</p>
                <ul>
                    <li><strong>Visual Processing:</strong> RGB and depth image analysis for obstacle detection</li>
                    <li><strong>LiDAR Processing:</strong> Point cloud analysis for 3D mapping and obstacle detection
                    </li>
                    <li><strong>Sensor Fusion:</strong> Kalman filtering for robust state estimation</li>
                    <li><strong>Object Tracking:</strong> Multi-object tracking for dynamic obstacle avoidance</li>
                </ul>

                <h3>Navigation Architecture</h3>
                <p>The navigation system consists of:</p>
                <ul>
                    <li>Global path planner for facility-wide navigation</li>
                    <li>Local path planner for dynamic obstacle avoidance (TEB/DWA)</li>
                    <li>Kinematic controller for smooth motion profiles</li>
                    <li>Safety-rated stop system</li>
                </ul>
            </div>

            <!-- Results -->
            <div class="case-study-section">
                <h2>Results & Impact</h2>
                <div class="tech-stack">
                    <div class="tech-item">
                        <h4>99.0%</h4>
                        <p>Collision Avoidance Rate</p>
                    </div>
                    <div class="tech-item">
                        <h4>15ms</h4>
                        <p>Obstacle Detection Latency</p>
                    </div>
                    <div class="tech-item">
                        <h4>2cm</h4>
                        <p>Position Accuracy</p>
                    </div>
                    <div class="tech-item">
                        <h4>8 hours</h4>
                        <p>Continuous Operation Time</p>
                    </div>
                </div>

                <h3>Performance Metrics</h3>
                <ul>
                    <li>Successfully completed 5,000+ km of autonomous travel</li>
                    <li>Reduced material handling costs by 40%</li>
                    <li>Achieved 99.0% collision avoidance in mixed traffic</li>
                    <li>Maintained 2cm docking accuracy</li>
                    <li>Processed obstacle detection in under 15ms</li>
                </ul>
            </div>

            <!-- Safety Features -->
            <div class="case-study-section">
                <h2>Safety Features</h2>
                <p>The system includes comprehensive safety mechanisms:</p>
                <ul>
                    <li><strong>Emergency Stop:</strong> Hardware-level e-stop for immediate halting</li>
                    <li><strong>Safety Zones:</strong> Dynamic speed reduction in high-traffic areas</li>
                    <li><strong>Battery Management:</strong> Autonomous charging when battery is low</li>
                    <li><strong>Load Stability:</strong> Active monitoring of payload stability</li>
                    <li><strong>Manual Override:</strong> Joystick control for manual maneuvering</li>
                </ul>
            </div>

            <!-- Applications -->
            <div class="case-study-section">
                <h2>Applications</h2>
                <p>The autonomous navigation system enables various applications:</p>
                <ul>
                    <li><strong>Intralogistics:</strong> Automated material transport in factories</li>
                    <li><strong>E-commerce Fulfillment:</strong> Goods-to-person picking systems</li>
                    <li><strong>Hospital Logistics:</strong> Autonomous delivery of medicine and linens</li>
                    <li><strong>Retail Inventory:</strong> Shelf scanning and stock monitoring</li>
                    <li><strong>Disinfection:</strong> Autonomous UV-C disinfection robots</li>
                </ul>
            </div>

            <!-- Future Enhancements -->
            <div class="case-study-section">
                <h2>Future Enhancements</h2>
                <p>Planned improvements include:</p>
                <ul>
                    <li>Fleet management for multi-robot coordination</li>
                    <li>Advanced semantic mapping for better context understanding</li>
                    <li>Integration with 5G for low-latency cloud processing</li>
                    <li>Reinforcement learning for optimized path planning</li>
                    <li>Opportunity charging optimization</li>
                </ul>
            </div>
        </div>
    </section>

    <script src="../js/script.js"></script>
</body>

</html>