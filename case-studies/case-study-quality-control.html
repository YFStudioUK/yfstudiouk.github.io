<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Industrial Quality Control - YF Studio Case Study</title>
    <meta name="description"
        content="High-speed computer vision pipeline for automated defect detection in manufacturing.">

    <!-- Open Graph / Facebook -->
    <meta property="og:type" content="article">
    <meta property="og:url" content="https://yfstudiouk.github.io/case-studies/case-study-quality-control.html">
    <meta property="og:title" content="Industrial Quality Control - YF Studio Case Study">
    <meta property="og:description"
        content="High-speed computer vision pipeline for automated defect detection in manufacturing.">
    <meta property="og:image" content="https://yfstudiouk.github.io/images/og-image.jpg">

    <!-- Twitter -->
    <meta property="twitter:card" content="summary_large_image">
    <meta property="twitter:url" content="https://yfstudiouk.github.io/case-studies/case-study-quality-control.html">
    <meta property="twitter:title" content="Industrial Quality Control - YF Studio Case Study">
    <meta property="twitter:description"
        content="High-speed computer vision pipeline for automated defect detection in manufacturing.">
    <meta property="twitter:image" content="https://yfstudiouk.github.io/images/og-image.jpg">

    <!-- Canonical & Robots -->
    <link rel="canonical" href="https://yfstudiouk.github.io/case-studies/case-study-quality-control.html">
    <meta name="robots" content="index, follow">

    <link rel="stylesheet" href="../css/styles.css">
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&display=swap" rel="stylesheet">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css">

    <!-- Google Analytics -->
    <script src="../js/analytics.js"></script>


    <style>
        .case-study-hero {
            min-height: 60vh;
            display: flex;
            align-items: center;
            background:
                radial-gradient(circle at 20% 80%, rgba(0, 255, 255, 0.15) 0%, transparent 50%),
                radial-gradient(circle at 80% 20%, rgba(255, 0, 255, 0.1) 0%, transparent 50%),
                radial-gradient(circle at 40% 40%, rgba(128, 0, 255, 0.1) 0%, transparent 50%),
                radial-gradient(circle at 60% 60%, rgba(0, 0, 255, 0.08) 0%, transparent 50%),
                linear-gradient(135deg, #000000 0%, #0a0a0a 25%, #1a1a1a 50%, #0d1117 75%, #161b22 100%);
            color: #ff00ff;
            position: relative;
            overflow: hidden;
            border-bottom: 1px solid rgba(255, 0, 255, 0.2);
        }

        .case-study-content {
            padding: 4rem 0;
            background: linear-gradient(135deg, #000000 0%, #0a0a0a 25%, #1a1a1a 50%, #0d1117 75%, #161b22 100%);
            color: white;
        }

        .case-study-section {
            margin-bottom: 3rem;
        }

        .case-study-section h2 {
            background: linear-gradient(45deg, #ff00ff, #00ffff);
            -webkit-background-clip: text;
            -webkit-text-fill-color: transparent;
            background-clip: text;
            font-size: 2rem;
            margin-bottom: 1rem;
        }

        .case-study-section h3 {
            color: #00ffff;
            font-size: 1.5rem;
            margin-bottom: 1rem;
        }

        .tech-stack {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(200px, 1fr));
            gap: 1rem;
            margin: 2rem 0;
        }

        .tech-item {
            background: rgba(255, 0, 255, 0.1);
            border: 1px solid rgba(255, 0, 255, 0.3);
            padding: 1rem;
            border-radius: 10px;
            text-align: center;
        }

        .back-button {
            position: fixed;
            top: 20px;
            left: 20px;
            background: linear-gradient(135deg, #000000 0%, #1a1a1a 100%);
            color: #ff00ff;
            border: 2px solid rgba(255, 0, 255, 0.4);
            padding: 0.8rem 1.5rem;
            border-radius: 25px;
            text-decoration: none;
            font-weight: 600;
            box-shadow: 0 5px 15px rgba(255, 0, 255, 0.3);
            transition: all 0.3s ease;
            z-index: 1000;
        }

        .back-button:hover {
            background: linear-gradient(135deg, #ff00ff, #00ffff);
            color: #000000;
            transform: translateY(-2px);
            box-shadow: 0 8px 25px rgba(255, 0, 255, 0.5);
        }

        .case-study-section ul {
            padding-left: 2rem;
        }

        .case-study-section li {
            margin-bottom: 0.5rem;
        }

        .case-study-section h3 {
            margin-top: 2rem;
            margin-bottom: 1rem;
        }

        .case-study-section h3:first-child {
            margin-top: 0;
        }
    </style>
</head>

<body>
    <a href="../index.html" class="back-button">
        <i class="fas fa-arrow-left"></i> Back to Portfolio
    </a>

    <!-- Case Study Hero -->
    <section class="case-study-hero">
        <div class="container">
            <div class="hero-content">
                <h1 class="hero-title">
                    Industrial Quality Control System
                    <span class="gradient-text">Computer Vision Solution</span>
                </h1>
                <p class="hero-description">
                    Automated defect detection system for manufacturing lines with 99.4% accuracy,
                    processing 1000+ products per minute with real-time quality assessment.
                </p>
            </div>
        </div>
    </section>

    <!-- Case Study Content -->
    <section class="case-study-content">
        <div class="container">
            <!-- Project Context -->
            <div class="case-study-section">
                <h2>Project Context</h2>
                <p>A Tier 1 automotive parts supplier in the West Midlands engaged YF Studio for a 5-month engagement
                    from January to May 2024 to replace their manual inspection process with an automated computer
                    vision system. The client produces precision-machined engine brackets and housings for two major
                    OEMs, running three production lines across a single facility with output of approximately 18,000
                    parts per shift.</p>
                <div class="tech-stack">
                    <div class="tech-item">
                        <h4>Timeline</h4>
                        <p>5 months (Jan &ndash; May 2024)</p>
                    </div>
                    <div class="tech-item">
                        <h4>Team</h4>
                        <p>2 computer vision engineers, 1 integration specialist</p>
                    </div>
                    <div class="tech-item">
                        <h4>Industry</h4>
                        <p>Automotive parts manufacturing (Tier 1 supplier)</p>
                    </div>
                </div>
            </div>

            <!-- Project Overview -->
            <div class="case-study-section">
                <h2>Project Overview</h2>
                <p>Developed a comprehensive computer vision system for automated quality control in automotive parts
                    manufacturing. The system detects surface defects, dimensional variations, and assembly issues in
                    real-time, ensuring consistent product quality while reducing manual inspection costs.</p>

                <div class="tech-stack">
                    <div class="tech-item">
                        <h4>Hardware</h4>
                        <p>Industrial PCs, High-res Cameras, LED Lighting Systems</p>
                    </div>
                    <div class="tech-item">
                        <h4>AI Framework</h4>
                        <p>PyTorch, TensorFlow, OpenCV, Scikit-learn</p>
                    </div>
                    <div class="tech-item">
                        <h4>Computer Vision</h4>
                        <p>ResNet, EfficientNet, YOLOv7, Image Segmentation</p>
                    </div>
                    <div class="tech-item">
                        <h4>Integration</h4>
                        <p>PLC Communication, SCADA Systems, MES</p>
                    </div>
                </div>
            </div>

            <!-- Challenge -->
            <div class="case-study-section">
                <h2>The Challenge</h2>
                <p>The client's existing quality control relied on a team of six manual inspectors working in
                    rotation, achieving roughly 87% defect detection rates with significant variability between shifts.
                    A previous attempt to introduce a rule-based machine vision system (using simple thresholding and
                    template matching) had been trialled in 2022 but was abandoned after three months &mdash; it could
                    not cope with the natural variation in part surfaces and produced an unacceptable false rejection
                    rate of over 12%, causing costly production stoppages.</p>
                <p>Lighting proved to be a critical obstacle in the facility. Harsh fluorescent overhead lighting
                    created specular reflections on machined aluminium surfaces, while shadows cast by conveyor belt
                    mechanisms and overhead gantries varied depending on part position. Colour temperature also shifted
                    noticeably between the three production lines due to different fixture ages and bulb types. Any
                    viable solution had to be robust to these conditions without requiring a full lighting retrofit
                    across the plant.</p>
                <p>Key requirements included:</p>
                <ul>
                    <li>Detecting micro-defects as small as 0.1mm on machined aluminium surfaces</li>
                    <li>Processing 1,000+ parts per minute across three production lines</li>
                    <li>Handling variable lighting conditions, surface finishes, and reflective materials</li>
                    <li>Achieving a false rejection rate below 1% to avoid production delays</li>
                    <li>Integration with existing PLC/SCADA infrastructure and MES reporting</li>
                    <li>Compliance with IATF 16949 automotive quality standards</li>
                </ul>
            </div>

            <!-- Solution -->
            <div class="case-study-section">
                <h2>Our Solution</h2>
                <h3>1. Multi-Camera Inspection System</h3>
                <p>Deployed a synchronized 6-camera setup with diffused LED dome lighting at each inspection station,
                    replacing the reliance on ambient fluorescent lighting. Dome illumination was chosen over directional
                    ring lights because it minimises specular highlights on curved aluminium surfaces &mdash; a critical
                    requirement identified during the site survey. Each camera captures at 5 megapixels and 60 fps,
                    positioned at optimised angles (0&deg;, 30&deg;, 60&deg; from vertical, with two lateral views) to
                    ensure full surface coverage. We evaluated line-scan cameras as an alternative but ruled them out
                    due to the variable conveyor speed on Line 2, which would have required complex encoder
                    synchronisation.</p>

                <h3>2. Advanced Defect Detection Models</h3>
                <p>Developed custom CNN models based on EfficientNet-B3 as the backbone, selected over ResNet-50 for its
                    superior accuracy-to-compute ratio &mdash; critical given the per-station budget constraints on
                    inference hardware. The models were trained on 50,000 annotated images of defective and non-defective
                    parts, covering 15 defect categories including scratches, dents, porosity, burrs, corrosion spots,
                    and dimensional variations. The annotation was carried out over 3 weeks by a team of 2 annotators
                    using CVAT (Computer Vision Annotation Tool), with a structured QA review pass that rejected
                    approximately 8% of initial labels due to ambiguous defect boundaries or mislabelling. We also
                    applied offline augmentation (rotation, brightness jitter, synthetic shadow overlays) to improve
                    robustness to the lighting variability observed across the three production lines.</p>

                <h3>3. Real-time Processing Pipeline</h3>
                <p>Implemented a high-performance processing pipeline using TensorRT for model inference on NVIDIA T4
                    GPUs, achieving sub-60ms end-to-end latency per part. TensorRT was chosen over ONNX Runtime because
                    it delivered approximately 35% lower latency on the target hardware in our benchmarks. The pipeline
                    is structured as an asynchronous queue to decouple image acquisition from inference, preventing
                    camera frame drops during peak throughput.</p>

                <h3>4. Intelligent Classification System</h3>
                <p>Created a hierarchical classification system that categorises defects by severity (critical, major,
                    minor) and type, enabling automated sorting into pass, rework, and reject bins. The severity
                    thresholds were calibrated in collaboration with the client's quality engineering team to align with
                    their existing IATF 16949 nonconformance criteria, ensuring the automated system's decisions were
                    directly comparable to historical manual inspection records.</p>
            </div>

            <!-- Technical Implementation -->
            <div class="case-study-section">
                <h2>Technical Implementation</h2>
                <h3>Image Processing Pipeline</h3>
                <p>The system processes images through multiple stages:</p>
                <ul>
                    <li><strong>Preprocessing:</strong> Noise reduction, contrast enhancement, and normalization</li>
                    <li><strong>Feature Extraction:</strong> Edge detection, texture analysis, and geometric
                        measurements</li>
                    <li><strong>Classification:</strong> Multi-class defect detection using ensemble models</li>
                    <li><strong>Post-processing:</strong> Confidence scoring and decision making</li>
                </ul>

                <h3>Model Architecture</h3>
                <p>Implemented a hybrid approach combining:</p>
                <ul>
                    <li>EfficientNet-B3 backbone for feature extraction (pretrained on ImageNet, fine-tuned on domain data)</li>
                    <li>Custom spatial attention modules for defect localisation within the part region of interest</li>
                    <li>Ensemble of 3 models (varying augmentation seeds) for improved accuracy and reduced variance</li>
                    <li>Transfer learning with progressive unfreezing to retain low-level feature representations</li>
                </ul>

                <h3>Limitations &amp; Edge Cases</h3>
                <p>While the system achieves strong overall performance, several known limitations were documented during
                    acceptance testing:</p>
                <ul>
                    <li><strong>Reflective surfaces:</strong> Performance drops to 96.2% detection accuracy on
                        chrome-plated and highly reflective surfaces due to specular highlights saturating the camera
                        sensor. A polarising filter attachment is recommended for production lines handling these part
                        types, and is planned for retrofit in Q3 2024.</li>
                    <li><strong>Novel defect types:</strong> The system is trained on 15 known defect categories. Entirely
                        novel defect types (e.g., a new supplier's material exhibiting unfamiliar grain patterns) may be
                        classified as "unknown" and flagged for human review rather than auto-rejected.</li>
                    <li><strong>Part changeover:</strong> When switching between significantly different part geometries,
                        a 15-minute recalibration cycle is required to update the region-of-interest templates. This is
                        handled automatically but adds downtime during product changeovers.</li>
                    <li><strong>Ambient light interference:</strong> Although the dome lighting largely isolates the
                        inspection zone, direct sunlight from nearby loading bay doors during summer months caused a
                        measurable (0.3%) accuracy dip in acceptance testing. Blackout curtains were recommended for the
                        affected station.</li>
                </ul>
            </div>

            <!-- Results -->
            <div class="case-study-section">
                <h2>Results &amp; Impact</h2>
                <div class="tech-stack">
                    <div class="tech-item">
                        <h4>99.4%</h4>
                        <p>Detection Accuracy</p>
                        <p style="font-size: 0.8rem; color: #aaa;">Baseline: 87% (manual)</p>
                    </div>
                    <div class="tech-item">
                        <h4>&lt;60ms</h4>
                        <p>Processing Time per Part</p>
                        <p style="font-size: 0.8rem; color: #aaa;">Baseline: 4&ndash;6 sec (manual)</p>
                    </div>
                    <div class="tech-item">
                        <h4>0.1mm</h4>
                        <p>Minimum Defect Size</p>
                        <p style="font-size: 0.8rem; color: #aaa;">Baseline: ~0.5mm (manual)</p>
                    </div>
                    <div class="tech-item">
                        <h4>0.6%</h4>
                        <p>False Rejection Rate</p>
                        <p style="font-size: 0.8rem; color: #aaa;">Baseline: 12% (rule-based system)</p>
                    </div>
                </div>

                <h3>Business Impact</h3>
                <ul>
                    <li>Reduced manual inspection headcount from 6 inspectors per shift to 1 supervisor overseeing
                        the automated system &mdash; an estimated 70% reduction in inspection labour costs</li>
                    <li>Improved defect detection consistency: shift-to-shift detection variance dropped from &pm;8%
                        (manual) to &pm;0.3% (automated)</li>
                    <li>Decreased false rejection rate from 12% (previous rule-based system) to 0.6%, significantly
                        reducing unnecessary rework and scrap costs</li>
                    <li>Enabled 24/7 quality monitoring across all three production lines without human fatigue
                        degradation</li>
                    <li>Generated per-part traceability logs and shift-level quality analytics, supporting the
                        client's IATF 16949 audit requirements</li>
                </ul>
            </div>

            <!-- Quality Metrics -->
            <div class="case-study-section">
                <h2>Quality Metrics</h2>
                <p>The system maintains strong performance across all quality indicators, validated against a held-out
                    test set of 5,000 images and confirmed during a 2-week parallel run alongside manual inspectors:</p>
                <ul>
                    <li><strong>Precision:</strong> 98.8% &mdash; Low false positive rate, minimising unnecessary
                        rejections</li>
                    <li><strong>Recall:</strong> 99.4% &mdash; Captures the vast majority of genuine defects</li>
                    <li><strong>F1-Score:</strong> 99.1% &mdash; Strong balance of precision and recall</li>
                    <li><strong>System Availability:</strong> 99.2% &mdash; Accounts for planned recalibration and
                        occasional camera cleaning cycles</li>
                    <li><strong>Mean Time to Detection:</strong> 45ms &mdash; Well within the 60ms budget required
                        for line-speed operation</li>
                </ul>
            </div>

            <!-- Ongoing & Next Steps -->
            <div class="case-study-section">
                <h2>Ongoing &amp; Next Steps</h2>
                <p>Following successful deployment, YF Studio continues to support the client with model maintenance
                    and planned enhancements:</p>
                <ul>
                    <li><strong>Reflective surface retrofit (Q3 2024):</strong> Installing polarising filter
                        attachments on Line 3 to address the 96.2% accuracy limitation on chrome-plated parts</li>
                    <li><strong>Model retraining pipeline:</strong> Quarterly retraining on newly collected edge-case
                        images to maintain accuracy as part geometry and supplier materials evolve</li>
                    <li><strong>3D defect analysis:</strong> Evaluating structured light scanning for volumetric
                        defect measurement (depth of scratches and dents), expected to enter pilot in early 2025</li>
                    <li><strong>Predictive quality analytics:</strong> Correlating defect trends with upstream
                        process parameters (CNC tool wear, material batch) to enable proactive intervention before
                        defect rates rise</li>
                    <li><strong>Second facility rollout:</strong> The client has requested a scoping study for
                        deploying the system at their second manufacturing site in the East Midlands</li>
                </ul>
            </div>
        </div>
    </section>


</body>

</html>